{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOiESqaeEcbcRCjI65OyftV"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["#ResNext + LSTM 모델을 활용"],"metadata":{"id":"oI7CM6qx1Dbr"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qi9Qa0RY079D","executionInfo":{"status":"ok","timestamp":1714997796605,"user_tz":-540,"elapsed":23170,"user":{"displayName":"강승민","userId":"05010146225716091523"}},"outputId":"9723ca4b-6104-42a6-ced5-dbef917d9869"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount(\"/content/drive\")"]},{"cell_type":"code","source":["!pip install face_recognition"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"j8zzqtmd1cgI","executionInfo":{"status":"ok","timestamp":1714997991987,"user_tz":-540,"elapsed":35844,"user":{"displayName":"강승민","userId":"05010146225716091523"}},"outputId":"4bd93ffa-6b3f-4ef2-e62e-8063c7f4ee76"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting face_recognition\n","  Downloading face_recognition-1.3.0-py2.py3-none-any.whl (15 kB)\n","Collecting face-recognition-models>=0.3.0 (from face_recognition)\n","  Downloading face_recognition_models-0.3.0.tar.gz (100.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.1/100.1 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: Click>=6.0 in /usr/local/lib/python3.10/dist-packages (from face_recognition) (8.1.7)\n","Requirement already satisfied: dlib>=19.7 in /usr/local/lib/python3.10/dist-packages (from face_recognition) (19.24.4)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from face_recognition) (1.25.2)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from face_recognition) (9.4.0)\n","Building wheels for collected packages: face-recognition-models\n","  Building wheel for face-recognition-models (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for face-recognition-models: filename=face_recognition_models-0.3.0-py2.py3-none-any.whl size=100566170 sha256=26bb28769174d57fd3347a340996d9eb382cd6e9387990efde1cb2cdb40372f8\n","  Stored in directory: /root/.cache/pip/wheels/7a/eb/cf/e9eced74122b679557f597bb7c8e4c739cfcac526db1fd523d\n","Successfully built face-recognition-models\n","Installing collected packages: face-recognition-models, face_recognition\n","Successfully installed face-recognition-models-0.3.0 face_recognition-1.3.0\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"5Dv2sDD_4rQ4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#THis code is to check if the video is corrupted or not..\n","#If the video is corrupted delete the video.\n","import glob\n","import torch\n","import torchvision\n","from torchvision import transforms\n","from torch.utils.data import DataLoader\n","from torch.utils.data.dataset import Dataset\n","import os\n","import numpy as np\n","import cv2\n","import matplotlib.pyplot as plt\n","import face_recognition\n","\n","#Check if the file is corrupted or not\n","def validate_video(vid_path,train_transforms):\n","      transform = train_transforms\n","      count = 20\n","      video_path = vid_path\n","      frames = []\n","      a = int(100/count)\n","      first_frame = np.random.randint(0,a)\n","      temp_video = video_path.split('/')[-1]\n","      for i,frame in enumerate(frame_extract(video_path)):\n","        frames.append(transform(frame))\n","        if(len(frames) == count):\n","          break\n","          frames = torch.stack(frames)\n","      frames = frames[:count]\n","      return frames\n","#extract a from from video\n","def frame_extract(path):\n","  vidObj = cv2.VideoCapture(path)\n","  success = 1\n","  while success:\n","      success, image = vidObj.read()\n","      if success:\n","          yield image\n","\n","im_size = 112 #우리 이미지는 256 x 256\n","mean = [0.485, 0.456, 0.406]\n","std = [0.229, 0.224, 0.225]\n","\n","train_transforms = transforms.Compose([\n","                                        transforms.ToPILImage(),\n","                                        transforms.Resize((im_size,im_size)),\n","                                        transforms.ToTensor(),\n","                                        transforms.Normalize(mean,std)])\n","video_fil =  glob.glob('/content/drive/My Drive/Celeb_fake_face_only/*.mp4')\n","video_fil += glob.glob('/content/drive/My Drive/Celeb_real_face_only/*.mp4')\n","video_fil += glob.glob('/content/drive/My Drive/DFDC_FAKE_Face_only_data/*.mp4')\n","video_fil += glob.glob('/content/drive/My Drive/DFDC_REAL_Face_only_data/*.mp4')\n","video_fil += glob.glob('/content/drive/My Drive/FF_Face_only_data/*.mp4')\n","print(\"Total no of videos :\" , len(video_fil))\n","print(video_fil)\n","count = 0;\n","for i in video_fil:\n","  try:\n","    count+=1\n","    validate_video(i,train_transforms)\n","  except:\n","    print(\"Number of video processed: \" , count ,\" Remaining : \" , (len(video_fil) - count))\n","    print(\"Corrupted video is : \" , i)\n","    continue\n","print((len(video_fil) - count))"],"metadata":{"id":"TpVSdhyO2Ae_"},"execution_count":null,"outputs":[]}]}
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#before running this please change the RUNTIME to GPU (Runtime -> Change runtime type -> set harware accelarotor as GPU)\n",
    "#Mount our google drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "!pip3 install face_recognition\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torchvision import model\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.autofrad import Variable\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import face_recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torchvision import models\n",
    "\n",
    "class ImageModel(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(ImageModel, self).__init__()\n",
    "        model = models.resnext50_32x4d(pretrained=True)\n",
    "        self.features = nn.Sequential(*list(model.children())[:-2])\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.classifier = nn.Linear(2048, num_classes)\n",
    "        self.relu = nn.LeakyReLU()\n",
    "        self.dp = nn.Dropout(0.4)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.dp(self.relu(x))\n",
    "        x = self.classifier(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_size = 224\n",
    "mean=[0.485, 0.456, 0.406]\n",
    "std=[0.229, 0.224, 0.225]\n",
    "sm = nn.Softmax()\n",
    "inv_normalize =  transforms.Normalize(mean=-1*np.divide(mean,std),std=np.divide([1,1,1],std))\n",
    "\n",
    "def predict(model,img,path = './'):\n",
    "  fmap,logits = model(img.to('cuda'))\n",
    "  params = list(model.parameters())\n",
    "  weight_softmax = model.linear1.weight.detach().cpu().numpy()\n",
    "  logits = sm(logits)\n",
    "  _,prediction = torch.max(logits,1)\n",
    "  confidence = logits[:,int(prediction.item())].item()*100\n",
    "  print('confidence of prediction:',logits[:,int(prediction.item())].item()*100)\n",
    "\n",
    "  idx = np.argmax(logits.detach().cpu().numpy())\n",
    "  bz, nc, h, w = fmap.shape\n",
    "  out = np.dot(fmap[-1].detach().cpu().numpy().reshape((nc, h*w)).T,weight_softmax[idx,:].T)\n",
    "  predict = out.reshape(h,w)\n",
    "  predict = predict - np.min(predict)\n",
    "  predict_img = predict / np.max(predict)\n",
    "  predict_img = np.uint8(255*predict_img)\n",
    "  out = cv2.resize(predict_img, (im_size,im_size))\n",
    "  heatmap = cv2.applyColorMap(out, cv2.COLORMAP_JET)\n",
    "  img = im_convert(img[:,-1,:,:,:])\n",
    "  result = heatmap * 0.5 + img*0.8*255\n",
    "  cv2.imwrite('/content/1.png',result)\n",
    "  result1 = heatmap * 0.5/255 + img*0.8\n",
    "  r,g,b = cv2.split(result1)\n",
    "  result1 = cv2.merge((r,g,b))\n",
    "  plt.imshow(result1)\n",
    "  plt.show()\n",
    "  return [int(prediction.item()),confidence]\n",
    "#img = train_data[100][0].unsqueeze(0)\n",
    "#predict(model,img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the image name and labels from csv\n",
    "class image_dataset(Dataset):\n",
    "    def __init__(self,image_names,labels,transform = None):\n",
    "        self.image_names = image_names\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_names)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.image_names[idx]\n",
    "        parts = image_path.split('/')\n",
    "        desired_parts = parts[5:]  # 5번째 이후의 부분을 가져옴\n",
    "        new_file_path = '/'.join(desired_parts)\n",
    "        label_info = self.labels.loc[self.labels['path'].values == new_file_path]\n",
    "\n",
    "        label = 0  # Default label (혹시 라벨 정보가 없는 경우를 대비)\n",
    "        if not label_info.empty:\n",
    "            label_str = label_info['label_str'].values[0]\n",
    "            if label_str == 'real':\n",
    "                label = 1\n",
    "            elif label_str == 'fake':\n",
    "                label = 0\n",
    "\n",
    "        # 이미지 불러오기\n",
    "        image = Image.open(image_path)  # PIL 라이브러리를 사용해 이미지를 불러옴\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code for making prediction\n",
    "im_size = 112\n",
    "mean=[0.485, 0.456, 0.406]\n",
    "std=[0.229, 0.224, 0.225]\n",
    "\n",
    "test_transforms = transforms.Compose([\n",
    "                                        transforms.ToTensor(),\n",
    "                                        transforms.CenterCrop(im_size),\n",
    "                                        transforms.Normalize(mean,std)])\n",
    "\n",
    "test_image_dirs = [\n",
    "    '/content/drive/MyDrive/datasets/test/real/',\n",
    "    '/content/drive/MyDrive/datasets/test/fake/'\n",
    "]\n",
    "\n",
    "#Get list of all test image files\n",
    "test_image_files = []  #image file들을 저장.(테스트 데이터만 저장을 한다)\n",
    "for dir_path in test_image_dirs:\n",
    "    test_image_files += glob.glob(os.path.join(dir_path, '*.jpg'))  # Assuming images are JPEG format\n",
    "\n",
    "header_list = [\"number\",\"original_path\",\"id\",\"label\",\"label_str\",\"path\"] #우리의 csv파일에 맞게 label list형태를 변환\n",
    "label_test = pd.read_csv('/content/drive/MyDrive/datasets/labels/test.csv', names = header_list)\n",
    "#필요한 부분만 가져간다.\n",
    "label_test = label_test.drop(columns=[\"number\", \"original_path\", \"id\"])\n",
    "\n",
    "test_images = image_dataset(test_image_files,label_test,transform = test_transforms)\n",
    "model = Model(2).cuda()\n",
    "#model을 불러오가.\n",
    "path_to_model = '/content/drive/MyDrive/datasets/checkpoint/checkpoint.pt'\n",
    "model.load_state_dict(torch.load(path_to_model))\n",
    "model.eval()\n",
    "for i in range(0,len(test_image_files)):\n",
    "  print(test_image_files[i])\n",
    "  prediction = predict(model,test_images[i],'./')\n",
    "  if prediction[0] == 1:\n",
    "    print(\"REAL\")\n",
    "  else:\n",
    "    print(\"FAKE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optional : If you want to pass full frame for prediction instead of face cropped frame\n",
    "#code for full frame processing\n",
    "class validation_dataset(Dataset):\n",
    "    def __init__(self,video_names,sequence_length = 60,transform = None):\n",
    "        self.video_names = video_names\n",
    "        self.transform = transform\n",
    "        self.count = sequence_length\n",
    "    def __len__(self):\n",
    "        return len(self.video_names)\n",
    "    def __getitem__(self,idx):\n",
    "        video_path = self.video_names[idx]\n",
    "        frames = []\n",
    "        a = int(100/self.count)\n",
    "        first_frame = np.random.randint(0,a)\n",
    "        for i,frame in enumerate(self.frame_extract(video_path)):\n",
    "          frames.append(self.transform(frame))\n",
    "          if(len(frames) == self.count):\n",
    "            break\n",
    "        frames = torch.stack(frames)\n",
    "        frames = frames[:self.count]\n",
    "        return frames.unsqueeze(0)\n",
    "    def frame_extract(self,path):\n",
    "      vidObj = cv2.VideoCapture(path)\n",
    "      success = 1\n",
    "      while success:\n",
    "          success, image = vidObj.read()\n",
    "          if success:\n",
    "              yield image"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
